--------------------------------------------------------------------------
START spark standaone
--------------------------------------------------------------------------

# start-slave.sh (spark standalone mode)
start-slave.sh spark://ubuntu:7077


--------------------------------------------------------------------------
START scala/spark shell
--------------------------------------------------------------------------

# start scala/spark shell
/opt/spark/bin/spark-shell
--
-- Spark session available as 'spark'.
-- Welcome to
--       ____              __
--      / __/__  ___ _____/ /__
--     _\ \/ _ \/ _ `/ __/  '_/
--    /___/ .__/\_,_/_/ /_/\_\   version 3.0.0-preview2
--       /_/
--          
-- Using Scala version 2.12.10 (OpenJDK 64-Bit Server VM, Java 1.8.0_242)
-- Type in expressions to have them evaluated.
-- Type :help for more information.
--
scala> 

# test scala println
scala> println("Hello Spark World")
-- Hello Spark World
scala> 

# exit scala shell
scala> :q


--------------------------------------------------------------------------
START pyspark shell
--------------------------------------------------------------------------

# start pyspark shell
/opt/spark/bin/pyspark
--
-- Welcome to
--       ____              __
--      / __/__  ___ _____/ /__
--     _\ \/ _ \/ _ `/ __/  '_/
--    /__ / .__/\_,_/_/ /_/\_\   version 3.0.0-preview2
--       /_/
-- 
-- Using Python version 3.6.9 (default, Nov  7 2019 10:44:02)
-- SparkSession available as 'spark'.
--
>>> 

# test python print
>>> print "Hello Pyspark World"
/-- Hello Pyspark World
>>> 

# exit pyspark shell
>>> exit()


--------------------------------------------------------------------------
START pyspark shell
--------------------------------------------------------------------------

# stop spark standalone
stop-slave.sh
-- stopping org.apache.spark.deploy.worker.Worker

--------------------------------------------------------------------------



